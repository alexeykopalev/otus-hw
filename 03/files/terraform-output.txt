alexey@home-ub22:~/Otus/otus-hw/03$ terraform apply

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # yandex_dns_recordset.rs-1 will be created
  + resource "yandex_dns_recordset" "rs-1" {
      + data    = [
          + "158.160.75.138",
        ]
      + id      = (known after apply)
      + name    = "dip-akopalev.ru."
      + ttl     = 600
      + type    = "A"
      + zone_id = (known after apply)
    }

  # yandex_dns_recordset.rs-2 will be created
  + resource "yandex_dns_recordset" "rs-2" {
      + data    = [
          + "dip-akopalev.ru",
        ]
      + id      = (known after apply)
      + name    = "www"
      + ttl     = 600
      + type    = "CNAME"
      + zone_id = (known after apply)
    }

  # yandex_dns_zone.zone1 will be created
  + resource "yandex_dns_zone" "zone1" {
      + created_at       = (known after apply)
      + description      = "Public zone"
      + folder_id        = (known after apply)
      + id               = (known after apply)
      + name             = "zone1"
      + private_networks = (known after apply)
      + public           = true
      + zone             = "dip-akopalev.ru."
    }

  # module.backend[0].yandex_compute_instance.vm will be created
  + resource "yandex_compute_instance" "vm" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "backend1"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "backend1"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd87t5gt48uc6feiibm8"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + metadata_options {
          + aws_v1_http_endpoint = (known after apply)
          + aws_v1_http_token    = (known after apply)
          + gce_http_endpoint    = (known after apply)
          + gce_http_token       = (known after apply)
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "10.10.1.10"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = false
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + host_affinity_rules = (known after apply)
          + placement_group_id  = (known after apply)
        }

      + resources {
          + core_fraction = 5
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = true
        }
    }

  # module.backend[1].yandex_compute_instance.vm will be created
  + resource "yandex_compute_instance" "vm" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "backend2"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "backend2"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd87t5gt48uc6feiibm8"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + metadata_options {
          + aws_v1_http_endpoint = (known after apply)
          + aws_v1_http_token    = (known after apply)
          + gce_http_endpoint    = (known after apply)
          + gce_http_token       = (known after apply)
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "10.10.1.11"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = false
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + host_affinity_rules = (known after apply)
          + placement_group_id  = (known after apply)
        }

      + resources {
          + core_fraction = 5
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = true
        }
    }

  # module.bast-host.yandex_compute_instance.vm will be created
  + resource "yandex_compute_instance" "vm" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "bast-host-srv"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "bast-host-srv"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd87t5gt48uc6feiibm8"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + metadata_options {
          + aws_v1_http_endpoint = (known after apply)
          + aws_v1_http_token    = (known after apply)
          + gce_http_endpoint    = (known after apply)
          + gce_http_token       = (known after apply)
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "172.16.16.254"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = true
          + nat_ip_address     = "158.160.84.164"
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + host_affinity_rules = (known after apply)
          + placement_group_id  = (known after apply)
        }

      + resources {
          + core_fraction = 20
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = false
        }
    }

  # module.db.yandex_compute_instance.vm will be created
  + resource "yandex_compute_instance" "vm" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "db-srv"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "db-srv"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd84nt41ssoaapgql97p"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + metadata_options {
          + aws_v1_http_endpoint = (known after apply)
          + aws_v1_http_token    = (known after apply)
          + gce_http_endpoint    = (known after apply)
          + gce_http_token       = (known after apply)
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "10.10.1.4"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = false
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + host_affinity_rules = (known after apply)
          + placement_group_id  = (known after apply)
        }

      + resources {
          + core_fraction = 5
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = true
        }
    }

  # module.network-create.yandex_vpc_gateway.nat_gateway will be created
  + resource "yandex_vpc_gateway" "nat_gateway" {
      + created_at = (known after apply)
      + folder_id  = (known after apply)
      + id         = (known after apply)
      + labels     = (known after apply)
      + name       = "test-gateway"

      + shared_egress_gateway {}
    }

  # module.network-create.yandex_vpc_network.network-1 will be created
  + resource "yandex_vpc_network" "network-1" {
      + created_at                = (known after apply)
      + default_security_group_id = (known after apply)
      + folder_id                 = (known after apply)
      + id                        = (known after apply)
      + labels                    = (known after apply)
      + name                      = "network1"
      + subnet_ids                = (known after apply)
    }

  # module.network-create.yandex_vpc_route_table.rt will be created
  + resource "yandex_vpc_route_table" "rt" {
      + created_at = (known after apply)
      + folder_id  = (known after apply)
      + id         = (known after apply)
      + labels     = (known after apply)
      + name       = "test-route-table"
      + network_id = (known after apply)

      + static_route {
          + destination_prefix = "0.0.0.0/0"
          + gateway_id         = (known after apply)
        }
    }

  # module.network-create.yandex_vpc_subnet.subnet-1 will be created
  + resource "yandex_vpc_subnet" "subnet-1" {
      + created_at     = (known after apply)
      + folder_id      = (known after apply)
      + id             = (known after apply)
      + labels         = (known after apply)
      + name           = "subnet-1"
      + network_id     = (known after apply)
      + route_table_id = (known after apply)
      + v4_cidr_blocks = [
          + "10.10.1.0/24",
        ]
      + v6_cidr_blocks = (known after apply)
      + zone           = "ru-central1-b"
    }

  # module.network-create.yandex_vpc_subnet.subnet-bast will be created
  + resource "yandex_vpc_subnet" "subnet-bast" {
      + created_at     = (known after apply)
      + folder_id      = (known after apply)
      + id             = (known after apply)
      + labels         = (known after apply)
      + name           = "subnet-bast"
      + network_id     = (known after apply)
      + v4_cidr_blocks = [
          + "172.16.16.0/24",
        ]
      + v6_cidr_blocks = (known after apply)
      + zone           = "ru-central1-b"
    }

  # module.nginx.yandex_compute_instance.vm will be created
  + resource "yandex_compute_instance" "vm" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "nginx-srv"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "nginx-srv"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd84nt41ssoaapgql97p"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + metadata_options {
          + aws_v1_http_endpoint = (known after apply)
          + aws_v1_http_token    = (known after apply)
          + gce_http_endpoint    = (known after apply)
          + gce_http_token       = (known after apply)
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "10.10.1.3"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = true
          + nat_ip_address     = "158.160.75.138"
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + host_affinity_rules = (known after apply)
          + placement_group_id  = (known after apply)
        }

      + resources {
          + core_fraction = 20
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = true
        }
    }

  # module.sg-create.yandex_vpc_security_group.external-sg will be created
  + resource "yandex_vpc_security_group" "external-sg" {
      + created_at = (known after apply)
      + folder_id  = (known after apply)
      + id         = (known after apply)
      + labels     = (known after apply)
      + name       = "external-sg"
      + network_id = (known after apply)
      + status     = (known after apply)

      + egress {
          + description    = "any"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ANY"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }

      + ingress {
          + description    = "allow http"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 80
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description       = "allow ssh bastion"
          + from_port         = -1
          + id                = (known after apply)
          + labels            = (known after apply)
          + port              = 22
          + protocol          = "TCP"
          + security_group_id = (known after apply)
          + to_port           = -1
          + v4_cidr_blocks    = []
          + v6_cidr_blocks    = []
        }
      + ingress {
          + description    = "ping allow"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ICMP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }
    }

  # module.sg-create.yandex_vpc_security_group.internal-sg will be created
  + resource "yandex_vpc_security_group" "internal-sg" {
      + created_at = (known after apply)
      + folder_id  = (known after apply)
      + id         = (known after apply)
      + labels     = (known after apply)
      + name       = "internal-sg"
      + network_id = (known after apply)
      + status     = (known after apply)

      + egress {
          + description    = "any"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ANY"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }

      + ingress {
          + description    = "allow 3306"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 3306
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "allow http"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 80
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description       = "allow ssh bastion"
          + from_port         = -1
          + id                = (known after apply)
          + labels            = (known after apply)
          + port              = 22
          + protocol          = "TCP"
          + security_group_id = (known after apply)
          + to_port           = -1
          + v4_cidr_blocks    = []
          + v6_cidr_blocks    = []
        }
      + ingress {
          + description    = "ping allow"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ICMP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }
    }

  # module.sg-create.yandex_vpc_security_group.sec-bast-sg will be created
  + resource "yandex_vpc_security_group" "sec-bast-sg" {
      + created_at = (known after apply)
      + folder_id  = (known after apply)
      + id         = (known after apply)
      + labels     = (known after apply)
      + name       = "sec-bast-sg"
      + network_id = (known after apply)
      + status     = (known after apply)

      + egress {
          + description    = "any"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ANY"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }

      + ingress {
          + description    = "ping allow"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ICMP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "ssh in"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 22
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }
    }

Plan: 16 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

yandex_dns_zone.zone1: Creating...
module.network-create.yandex_vpc_network.network-1: Creating...
module.network-create.yandex_vpc_gateway.nat_gateway: Creating...
yandex_dns_zone.zone1: Creation complete after 1s [id=dnscomceb96p842up5br]
yandex_dns_recordset.rs-1: Creating...
yandex_dns_recordset.rs-2: Creating...
module.network-create.yandex_vpc_gateway.nat_gateway: Creation complete after 1s [id=enpkq171ii8gigq8n66e]
yandex_dns_recordset.rs-2: Creation complete after 0s [id=dnscomceb96p842up5br/www/CNAME]
yandex_dns_recordset.rs-1: Creation complete after 1s [id=dnscomceb96p842up5br/dip-akopalev.ru./A]
module.network-create.yandex_vpc_network.network-1: Creation complete after 2s [id=enpaitc6r8bpnp796mm3]
module.network-create.yandex_vpc_route_table.rt: Creating...
module.network-create.yandex_vpc_subnet.subnet-bast: Creating...
module.sg-create.yandex_vpc_security_group.sec-bast-sg: Creating...
module.network-create.yandex_vpc_subnet.subnet-bast: Creation complete after 1s [id=e2lf0k5nic3rc6pf92or]
module.network-create.yandex_vpc_route_table.rt: Creation complete after 2s [id=enptqm7m5f73ir9qnrp5]
module.network-create.yandex_vpc_subnet.subnet-1: Creating...
module.sg-create.yandex_vpc_security_group.sec-bast-sg: Creation complete after 2s [id=enpga21jmpldghbqb6e0]
module.sg-create.yandex_vpc_security_group.external-sg: Creating...
module.bast-host.yandex_compute_instance.vm: Creating...
module.sg-create.yandex_vpc_security_group.internal-sg: Creating...
module.network-create.yandex_vpc_subnet.subnet-1: Creation complete after 1s [id=e2lu81gavt33vfklt6bt]
module.sg-create.yandex_vpc_security_group.external-sg: Creation complete after 1s [id=enpl3qslc68pg84t0voq]
module.sg-create.yandex_vpc_security_group.internal-sg: Creation complete after 4s [id=enp55kefpsfihhn81tlq]
module.backend[0].yandex_compute_instance.vm: Creating...
module.nginx.yandex_compute_instance.vm: Creating...
module.db.yandex_compute_instance.vm: Creating...
module.backend[1].yandex_compute_instance.vm: Creating...
module.bast-host.yandex_compute_instance.vm: Still creating... [10s elapsed]
module.db.yandex_compute_instance.vm: Still creating... [10s elapsed]
module.backend[0].yandex_compute_instance.vm: Still creating... [10s elapsed]
module.backend[1].yandex_compute_instance.vm: Still creating... [10s elapsed]
module.nginx.yandex_compute_instance.vm: Still creating... [10s elapsed]
module.bast-host.yandex_compute_instance.vm: Still creating... [20s elapsed]
module.backend[1].yandex_compute_instance.vm: Still creating... [20s elapsed]
module.db.yandex_compute_instance.vm: Still creating... [20s elapsed]
module.backend[0].yandex_compute_instance.vm: Still creating... [20s elapsed]
module.nginx.yandex_compute_instance.vm: Still creating... [20s elapsed]
module.bast-host.yandex_compute_instance.vm: Still creating... [30s elapsed]
module.nginx.yandex_compute_instance.vm: Still creating... [30s elapsed]
module.db.yandex_compute_instance.vm: Still creating... [30s elapsed]
module.backend[1].yandex_compute_instance.vm: Still creating... [30s elapsed]
module.backend[0].yandex_compute_instance.vm: Still creating... [30s elapsed]
module.bast-host.yandex_compute_instance.vm: Still creating... [40s elapsed]
module.backend[1].yandex_compute_instance.vm: Creation complete after 38s [id=epd10dhmvfv1unmpnoo0]
module.nginx.yandex_compute_instance.vm: Still creating... [40s elapsed]
module.db.yandex_compute_instance.vm: Still creating... [40s elapsed]
module.backend[0].yandex_compute_instance.vm: Still creating... [40s elapsed]
module.bast-host.yandex_compute_instance.vm: Creation complete after 45s [id=epdmd6icqhe0e8bdq901]
module.nginx.yandex_compute_instance.vm: Creation complete after 42s [id=epd375ksqus3nimm5kbj]
module.backend[0].yandex_compute_instance.vm: Creation complete after 42s [id=epdr282ai46mtbafqrn6]
module.db.yandex_compute_instance.vm: Creation complete after 43s [id=epdhn0o7ivpmsa2pi4gf]

Apply complete! Resources: 16 added, 0 changed, 0 destroyed.