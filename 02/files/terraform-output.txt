[alexey@vivobook-fedora 02]$ terraform apply

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # yandex_compute_disk.iscsi-disk will be created
  + resource "yandex_compute_disk" "iscsi-disk" {
      + block_size  = 4096
      + created_at  = (known after apply)
      + folder_id   = (known after apply)
      + id          = (known after apply)
      + name        = "iscsi-disk"
      + product_ids = (known after apply)
      + size        = 15
      + status      = (known after apply)
      + type        = "network-hdd"
      + zone        = "ru-central1-b"
    }

  # yandex_compute_instance.iscsi-srv will be created
  + resource "yandex_compute_instance" "iscsi-srv" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "iscsi-srv"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "iscsi-srv"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd83rqq627fa1mdphnog"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "10.10.1.3"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = false
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + resources {
          + core_fraction = 20
          + cores         = 2
          + memory        = 2
        }

      + secondary_disk {
          + auto_delete = false
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = "READ_WRITE"
        }
    }

  # module.bast-host.yandex_compute_instance.vm will be created
  + resource "yandex_compute_instance" "vm" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "bast-host-srv"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "bast-host-srv"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd83rqq627fa1mdphnog"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "172.16.16.254"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = true
          + nat_ip_address     = "158.160.84.164"
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + resources {
          + core_fraction = 20
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = false
        }
    }

  # module.network-create.yandex_vpc_gateway.nat_gateway will be created
  + resource "yandex_vpc_gateway" "nat_gateway" {
      + created_at = (known after apply)
      + folder_id  = (known after apply)
      + id         = (known after apply)
      + labels     = (known after apply)
      + name       = "test-gateway"

      + shared_egress_gateway {}
    }

  # module.network-create.yandex_vpc_network.network-1 will be created
  + resource "yandex_vpc_network" "network-1" {
      + created_at                = (known after apply)
      + default_security_group_id = (known after apply)
      + folder_id                 = (known after apply)
      + id                        = (known after apply)
      + labels                    = (known after apply)
      + name                      = "network1"
      + subnet_ids                = (known after apply)
    }

  # module.network-create.yandex_vpc_route_table.rt will be created
  + resource "yandex_vpc_route_table" "rt" {
      + created_at = (known after apply)
      + folder_id  = (known after apply)
      + id         = (known after apply)
      + labels     = (known after apply)
      + name       = "test-route-table"
      + network_id = (known after apply)

      + static_route {
          + destination_prefix = "0.0.0.0/0"
          + gateway_id         = (known after apply)
        }
    }

  # module.network-create.yandex_vpc_subnet.subnet-1 will be created
  + resource "yandex_vpc_subnet" "subnet-1" {
      + created_at     = (known after apply)
      + folder_id      = (known after apply)
      + id             = (known after apply)
      + labels         = (known after apply)
      + name           = "subnet-1"
      + network_id     = (known after apply)
      + route_table_id = (known after apply)
      + v4_cidr_blocks = [
          + "10.10.1.0/24",
        ]
      + v6_cidr_blocks = (known after apply)
      + zone           = "ru-central1-b"
    }

  # module.network-create.yandex_vpc_subnet.subnet-bast will be created
  + resource "yandex_vpc_subnet" "subnet-bast" {
      + created_at     = (known after apply)
      + folder_id      = (known after apply)
      + id             = (known after apply)
      + labels         = (known after apply)
      + name           = "subnet-bast"
      + network_id     = (known after apply)
      + v4_cidr_blocks = [
          + "172.16.16.0/24",
        ]
      + v6_cidr_blocks = (known after apply)
      + zone           = "ru-central1-b"
    }

  # module.pcs[0].yandex_compute_instance.vm will be created
  + resource "yandex_compute_instance" "vm" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "pcs1"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "pcs1"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd83rqq627fa1mdphnog"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "10.10.1.10"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = false
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + resources {
          + core_fraction = 5
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = true
        }
    }

  # module.pcs[1].yandex_compute_instance.vm will be created
  + resource "yandex_compute_instance" "vm" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "pcs2"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "pcs2"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd83rqq627fa1mdphnog"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "10.10.1.11"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = false
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + resources {
          + core_fraction = 5
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = true
        }
    }

  # module.pcs[2].yandex_compute_instance.vm will be created
  + resource "yandex_compute_instance" "vm" {
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + gpu_cluster_id            = (known after apply)
      + hostname                  = "pcs3"
      + id                        = (known after apply)
      + metadata                  = {
          + "user-data" = <<-EOT
                #cloud-config
                users:
                  - name: akopalev
                    groups: wheel
                    shell: /bin/bash
                    sudo: ['ALL=(ALL) NOPASSWD:ALL']
                    ssh_authorized_keys:
                      - ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCxHlMc4ySp0W7oIBf1aRAxdIaoFyx3IZ+PNpAvDgluLZxmNLJ22ImYIcQkloY9tLwhD6guIdkoWtSusrjPfAO5bEPwKfa5GI51Qoq76gZ5/KyMtnYAARDyuSbMjeqaAJaF71oGKC4032hTlXtvMf7wAy8nfrP3zrRE7PDsqLh5vuVctAa78SFHp92394GYU0LkeCbE8dN+RW7T1wFoK7jK2HfVfLZMXtiJT3pji7jtkB7SKW8hNCeojKylZSW/AQhEyo32aPjZHomtQDkJ4DPVkPiGmcpDtpQ5u0fm0soEkODlKzECiNZM2pQq/gRdSmvObMbCkot5yjS4+uAqxl4jnzJU57lWDtFrIvkBDGJ2Y564r/pctq9uWp/QSbPgEv8uT/QaIoVeYMO723HHSzLRPVslrQiwkCU1qTFFHFCA2OlGJLZF05mGEi7pDAv2EX6PmfTdKwh8IsamEUgZsYbo+/RWKi56VDFGsZttrW3kVQ9mYEUAgitkDWnwpFO8DVU= alexey@vivobook-fedora
            EOT
        }
      + name                      = "pcs3"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-b"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd83rqq627fa1mdphnog"
              + name        = (known after apply)
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-hdd"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "10.10.1.12"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = false
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + resources {
          + core_fraction = 5
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = true
        }
    }

  # module.sg-create.yandex_vpc_security_group.prom-sg will be created
  + resource "yandex_vpc_security_group" "prom-sg" {
      + created_at = (known after apply)
      + folder_id  = (known after apply)
      + id         = (known after apply)
      + labels     = (known after apply)
      + name       = "prom-sg"
      + network_id = (known after apply)
      + status     = (known after apply)

      + egress {
          + description    = "any"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ANY"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }

      + ingress {
          + description    = "allow CLVM"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 21064
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "allow booth ticket manager"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 9929
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "allow booth ticket manager"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 9929
          + protocol       = "UDP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "allow corosync multicast-udp"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 5404
          + protocol       = "UDP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "allow corosync"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 5405
          + protocol       = "UDP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "allow corosync-qnetd"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 5403
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "allow crmd port"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 3121
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "allow iscsi 3620"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 3260
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "allow pcsd port"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 2224
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "10.10.1.0/24",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description       = "allow ssh bastion"
          + from_port         = -1
          + id                = (known after apply)
          + labels            = (known after apply)
          + port              = 22
          + protocol          = "TCP"
          + security_group_id = (known after apply)
          + to_port           = -1
          + v4_cidr_blocks    = []
          + v6_cidr_blocks    = []
        }
      + ingress {
          + description    = "ping allow"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ICMP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }
    }

  # module.sg-create.yandex_vpc_security_group.sec-bast-sg will be created
  + resource "yandex_vpc_security_group" "sec-bast-sg" {
      + created_at = (known after apply)
      + folder_id  = (known after apply)
      + id         = (known after apply)
      + labels     = (known after apply)
      + name       = "sec-bast-sg"
      + network_id = (known after apply)
      + status     = (known after apply)

      + egress {
          + description    = "any"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ANY"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }

      + ingress {
          + description    = "ping allow"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = -1
          + protocol       = "ICMP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }
      + ingress {
          + description    = "ssh in"
          + from_port      = -1
          + id             = (known after apply)
          + labels         = (known after apply)
          + port           = 22
          + protocol       = "TCP"
          + to_port        = -1
          + v4_cidr_blocks = [
              + "0.0.0.0/0",
            ]
          + v6_cidr_blocks = []
        }
    }

Plan: 13 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

module.network-create.yandex_vpc_gateway.nat_gateway: Creating...
module.network-create.yandex_vpc_network.network-1: Creating...
yandex_compute_disk.iscsi-disk: Creating...
module.network-create.yandex_vpc_gateway.nat_gateway: Creation complete after 0s [id=enpkq1sneurfj1fah690]
module.network-create.yandex_vpc_network.network-1: Creation complete after 3s [id=enpcfu5nq8i79php75mk]
module.network-create.yandex_vpc_route_table.rt: Creating...
module.network-create.yandex_vpc_subnet.subnet-bast: Creating...
module.sg-create.yandex_vpc_security_group.sec-bast-sg: Creating...
module.network-create.yandex_vpc_route_table.rt: Creation complete after 1s [id=enpasj8f8bcnids4554v]
module.network-create.yandex_vpc_subnet.subnet-1: Creating...
module.network-create.yandex_vpc_subnet.subnet-bast: Creation complete after 2s [id=e2ljs2amfb9cql96d017]
module.network-create.yandex_vpc_subnet.subnet-1: Creation complete after 2s [id=e2lkat7sgqgtrou6iumf]
module.sg-create.yandex_vpc_security_group.sec-bast-sg: Creation complete after 3s [id=enppvo2ofjdl0t4sgqft]
module.bast-host.yandex_compute_instance.vm: Creating...
module.sg-create.yandex_vpc_security_group.prom-sg: Creating...
module.sg-create.yandex_vpc_security_group.prom-sg: Creation complete after 2s [id=enpi69v48viabk77e5ts]
module.pcs[2].yandex_compute_instance.vm: Creating...
module.pcs[1].yandex_compute_instance.vm: Creating...
module.pcs[0].yandex_compute_instance.vm: Creating...
yandex_compute_disk.iscsi-disk: Still creating... [10s elapsed]
yandex_compute_disk.iscsi-disk: Creation complete after 10s [id=epdh5ka80h7i3doikrch]
yandex_compute_instance.iscsi-srv: Creating...
module.bast-host.yandex_compute_instance.vm: Still creating... [10s elapsed]
module.pcs[0].yandex_compute_instance.vm: Still creating... [10s elapsed]
module.pcs[2].yandex_compute_instance.vm: Still creating... [10s elapsed]
module.pcs[1].yandex_compute_instance.vm: Still creating... [10s elapsed]
yandex_compute_instance.iscsi-srv: Still creating... [10s elapsed]
module.bast-host.yandex_compute_instance.vm: Still creating... [20s elapsed]
module.pcs[1].yandex_compute_instance.vm: Still creating... [20s elapsed]
module.pcs[2].yandex_compute_instance.vm: Still creating... [20s elapsed]
module.pcs[0].yandex_compute_instance.vm: Still creating... [20s elapsed]
yandex_compute_instance.iscsi-srv: Still creating... [20s elapsed]
module.bast-host.yandex_compute_instance.vm: Still creating... [30s elapsed]
module.pcs[2].yandex_compute_instance.vm: Still creating... [30s elapsed]
module.pcs[1].yandex_compute_instance.vm: Still creating... [30s elapsed]
module.pcs[0].yandex_compute_instance.vm: Still creating... [30s elapsed]
module.pcs[2].yandex_compute_instance.vm: Creation complete after 32s [id=epditbbr6hrr51is7o54]
yandex_compute_instance.iscsi-srv: Still creating... [30s elapsed]
module.pcs[0].yandex_compute_instance.vm: Creation complete after 35s [id=epdbg4frl7gsu2785v9l]
module.pcs[1].yandex_compute_instance.vm: Creation complete after 37s [id=epdchhcb3i35t77cp0hv]
module.bast-host.yandex_compute_instance.vm: Still creating... [40s elapsed]
yandex_compute_instance.iscsi-srv: Creation complete after 39s [id=epdolbdo770urtgm0ib0]
module.bast-host.yandex_compute_instance.vm: Still creating... [50s elapsed]
module.bast-host.yandex_compute_instance.vm: Still creating... [1m0s elapsed]
module.bast-host.yandex_compute_instance.vm: Creation complete after 1m1s [id=epd9lil0tfug45crvd6c]

Apply complete! Resources: 13 added, 0 changed, 0 destroyed.